{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Tellier\\ Thomas \\\\Turp\\ Henry \\\\Turquetil\\ Antoine $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD207 - Data Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I - Un problème de classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agissait de classifier des messages écrits pour des réseaux sociaux comme insultant envers une personne ou non. Le training set contenait 4415 échantillons et le test, 4414, et l'évaluation était simplement le pourcentage de bonne classification. Les librairies externes de machine learning n'étaient pas autorisées.\n",
    "\n",
    "On a assez vite remarqué que le données sont assez réduites. Par exemples, 30 échantillons représentent 0.67% du test, ce qui est supérieur à la différence finale entre le premier et le second sur le test public. Il était donc difficile de valider son score avec les méthodes usuelles sans soumettre et que la variance était très élevée. Par ailleurs, les données venaient d'un challenge Kaggle :\n",
    "\n",
    "https://www.kaggle.com/c/detecting-insults-in-social-commentary\n",
    "\n",
    "Les vainqueurs étaient d'accord après la compétition sur le fait que le hasard avait grandement décidé des premières places. C'est donc plus dans un esprit de découverte que de compétition acharnée que nous avons envisagé ce challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II - Stratégie et implémentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons dès le début décidé d'implémenter notre challenge en C++, et de l'héberger sur github :\n",
    "\n",
    "https://github.com/antoinux/data-challenge-winners\n",
    "\n",
    "Nous avons utilisé deux librairies externes : Armadillo pour les opérations matricielles rapides et Boost pour les regex. Armadillo est une librairie regroupant la plupart des libraires d'algère linéaires classiques (OpenBlas, Lapack, Arpack, SuperLU...) sous une interface d'utilisation de style Matlab plutôt performante.\n",
    "\n",
    "De manière générale, notre stratégie a été de tester les différentes approches sur scikit-learn et de sélectionner la meilleure à partir du score de validation croisée avant d'implémenter le strict nécessaire en C++. Pour l'implémentation, on se réferrait à la source et aux références de scikit pour être certain de ce qu'on faisait, et en comparant régulièrement les résultats des deux implémentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III - Le parsing et le preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing : Henry je t'en prie\n",
    "\n",
    "En ce qui concerne le stemming, on a essayé d'utiliser le stemmer de nltk, mais il ne s'est pas avéré plus efficace que de simplement tronquer les mots (du moins en validation). On s'en est donc finalement passé et l'implémentation est restée en C++ pur. Nous avons tout de même lemmatizé les mots en \"you\" avec une regex particulière.\n",
    "\n",
    "Nous avons utilisé comme feature les mots seuls et les bi-grams apparaissants "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV - Naive Bayes et la régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier classifier implémenté fut Naive Bayes version \"Bernoulli\" :\n",
    "\n",
    "http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "\n",
    "Son avantage en terme d'implémentation est de se résumer à une série d'opérations matricielles de nécessitant pas d'optimiser une fonction de coût. Ca a quand même été plus difficile que prévu de faire aussi performant que scikit car on a été surpris de l'implémentation utilisée, inspirée par ce lien, et qui prend en compte les mots n'apparaissant pas les phrases :\n",
    "\n",
    "http://nlp.stanford.edu/IR-book/html/htmledition/the-bernoulli-model-1.html\n",
    "\n",
    "Aussi, utiliser les log-probas est mieux car permet d'éviter les instabilités numériques et donne d'agréables formules matricielles en transformant les produits de lois indépendantes en de belles sommes.\n",
    "\n",
    "On s'est ensuite aperçu que la régression logistique alliée à une matrice de compte des occurances des mots/n-grams permettait était plus performante. En TP d'optimisation, on avait implémenté la méthode de Newton, ce qui n'a pas été d'une grande aide ici à cause du nombre de features des modèles (souvent supérieur à 10000). On s'est donc intéressé à l'implémentation de liblinear, sous-jacente à scikit-learn :\n",
    "\n",
    "https://www.csie.ntu.edu.tw/~cjlin/papers/liblinear.pdf\n",
    "\n",
    "Etant certains de la fonction de coût à optimiser, on a pu implémenter. La méthode d'optimisation a été une simple descente de gradient. Avec un pas constant, il arrivait que l'algorithme ne converge pas. On a remédier à ce problème en ajustant le pas à chaque étape suivant que la norme du gradient est en train de diminuer ou pas :\n",
    "\n",
    "alpha *= (norm_grad > old_norm ? -1 : 1)*correct_rate + 1.;\n",
    "\n",
    "Où alpha est le pas de la descente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## V - Résumé de la méthode adoptée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre meilleure soumission a été obtenue en suivant ces étapes :\n",
    "\n",
    "- Parsing\n",
    "- Troncature à 5 caractères de tous les mots\n",
    "- Stemming adapté aux mots de la famille \"you\"\n",
    "- Matrice de compte des occurances sur les mots seuls et les Bi-grams\n",
    "- Régression logistique\n",
    "- Seuil de probabilité à 0.5\n",
    "\n",
    "L'implémentation des n-grams sur les caractères augmente peut-être le score. L'ajustement du seuil après la régression logistique permet problement de gagner quelques points. Cet ajustement peut se faire simplement en maximisant le score sur la validation, ou de manière moins honnête en faisant beaucoup de soumissions avec des seuils différents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
